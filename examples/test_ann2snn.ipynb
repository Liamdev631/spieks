{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spieks.neurons import SpikingNeuron, IF\n",
    "from spieks.network import run_sim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from tqdm.notebook import tdqm, trange\n",
    "import numpy as np\n",
    "\n",
    "N = 512\n",
    "T = 1\n",
    "DT = 1e-2\n",
    "\n",
    "MAX_HZ = 10\n",
    "\n",
    "BS = 128\n",
    "LR = 1e-3\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTModel, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28 * 28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 10),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"tmp/best_mnist_model.pth\"\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = torchvision.datasets.MNIST(root='./tmp/', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./tmp/', train=False, transform=transform, download=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BS, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BS, shuffle=False)\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device ({device})')\n",
    "\n",
    "# Initialize model, criterion, optimizer\n",
    "model = MNISTModel().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "# Load model if it exists\n",
    "if os.path.exists(model_path):\n",
    "\tmodel.load_state_dict(torch.load(model_path))\n",
    "\tprint(\"Model loaded from file:\", model_path)\n",
    "else:\n",
    "\tbest_accuracy = 0\n",
    "\ttrain_losses, test_accuracies = [], []\n",
    "\n",
    "\t# Training loop\n",
    "\tfor epoch in trange(EPOCHS):\n",
    "\t\tmodel.train()\n",
    "\t\trunning_loss = 0.0\n",
    "\t\tfor inputs, targets in train_loader:\n",
    "\t\t\tinputs, targets = inputs.to(device), targets.to(device)\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\toutputs = model(inputs)\n",
    "\t\t\tloss = criterion(outputs, targets)\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\trunning_loss += loss.item()\n",
    "\t\ttrain_loss = running_loss / len(train_loader)\n",
    "\t\ttrain_losses.append(train_loss)\n",
    "\t\tscheduler.step()\n",
    "\t\t\n",
    "\t\t# Evaluate on test set\n",
    "\t\tmodel.eval()\n",
    "\t\tcorrect = 0\n",
    "\t\ttotal = 0\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tfor inputs, targets in test_loader:\n",
    "\t\t\t\tinputs, targets = inputs.to(device), targets.to(device)\n",
    "\t\t\t\toutputs = model(inputs)\n",
    "\t\t\t\t_, predicted = torch.max(outputs, 1)\n",
    "\t\t\t\ttotal += targets.size(0)\n",
    "\t\t\t\tcorrect += (predicted == targets).sum().item()\n",
    "\t\taccuracy = correct / total\n",
    "\t\ttest_accuracies.append(accuracy)\n",
    "\n",
    "\t\tprint(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {train_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\t\t# Save the model if it's the best so far\n",
    "\t\tif accuracy > best_accuracy:\n",
    "\t\t\tbest_accuracy = accuracy\n",
    "\t\t\ttorch.save(model.state_dict(), model_path)\n",
    "\t\t\t\n",
    "\tprint(\"Model saved with accuracy:\", best_accuracy)\n",
    "\t\n",
    "\t# Plot loss and accuracy\n",
    "\tplt.figure(figsize=(10, 5))\n",
    "\tplt.subplot(1, 2, 1)\n",
    "\tplt.plot(range(1, EPOCHS + 1), train_losses, label='Loss')\n",
    "\tplt.title(\"Training Loss\")\n",
    "\tplt.xlabel(\"Epoch\")\n",
    "\tplt.ylabel(\"Loss\")\n",
    "\tplt.legend()\n",
    "\n",
    "\tplt.subplot(1, 2, 2)\n",
    "\tplt.plot(range(1, EPOCHS + 1), test_accuracies, label='Accuracy')\n",
    "\tplt.title(\"Test Accuracy\")\n",
    "\tplt.xlabel(\"Epoch\")\n",
    "\tplt.ylabel(\"Accuracy\")\n",
    "\tplt.legend()\n",
    "\n",
    "\tplt.tight_layout()\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the ann to an snn by replacing all relu layers with IF neurons\n",
    "def swap_layers(model, old_layer_type: type[nn.Module], new_layer_type: type[nn.Module]):\n",
    "    for name, module in model.named_children():\n",
    "        if isinstance(module, old_layer_type):\n",
    "            setattr(model, name, new_layer_type(*module.parameters()))\n",
    "        elif isinstance(module, nn.Module):\n",
    "            swap_layers(module, old_layer_type, new_layer_type)\n",
    "    return model\n",
    "model = swap_layers(model, nn.ReLU, IF)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the accuracy after conversion\n",
    "def eval_snn(test_dataloader, model, loss_fn, device, sim_len=8, rank=0, batches=-1, dt=1.0):\n",
    "    tot = torch.zeros(sim_len).to(device)\n",
    "    loss = torch.zeros(sim_len).to(device)\n",
    "    length = 0\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (img, label) in enumerate(tqdm(test_dataloader)):\n",
    "            if batches > 0 and idx >= batches:\n",
    "                break\n",
    "            length += len(label)\n",
    "            img = img.to(device)\n",
    "            label = label.to(device)\n",
    "            spikes = torch.zeros_like(model(img))\n",
    "            time, activation = run_sim(model, img, )\n",
    "\t\t\t\n",
    "            #time = np.arange(1, sim_len + 1) * dt\n",
    "            #for i, t in enumerate(time):\n",
    "            #\tout = model(img)\n",
    "            #\tspikes += out\n",
    "            #\ttot[i] += (label==spikes.max(1)[1]).sum()\n",
    "            #\tloss[i] += loss_fn(spikes / t, label)\n",
    "            print('label:', label)\n",
    "            print('spikes:', spikes)\n",
    "            print('spikes.argmax(dim=1):', spikes.argmax(dim=1))\n",
    "    return tot.detach().cpu().numpy() / length, loss.detach().cpu().numpy() / length"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
